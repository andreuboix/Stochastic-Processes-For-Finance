{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726c4bbc",
   "metadata": {},
   "source": [
    "# Stochastic Processes for Finance: Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fcbbfa",
   "metadata": {},
   "source": [
    "Group 06: Alexander Robert Algmin Venegas (2871245) and Andreu Boix Torres (2868333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd1d4b",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6ebf7",
   "metadata": {},
   "source": [
    "The $\\textit{general linear stochastic differential equation}$ (SDE) is:\n",
    "\n",
    "\\begin{equation}\n",
    "dX_t = \\{ c_1(t) X_t + c_2(t) \\}dt + \\{\\sigma_1(t) X_t + \\sigma_2(t)\\}dW_t, \\quad t\\in[0,T],\n",
    "\\end{equation}\n",
    "\n",
    "with an initial condition $X_0$ and deterministic, continuous functions $c_1(t)$, $c_2(t)$, $\\sigma_1(t)$ and $\\sigma_2(t)$.\n",
    "We obtain the following SDE's as particular cases:\n",
    "\n",
    "- The Langevin SDE if $c_1(t) = c$, $c_2(t) = 0$, $\\sigma_1(t) = 0$, $\\sigma_2(t) = \\sigma$ for constants $c,\\sigma$.\n",
    "- The Vasicek interest rate model $dr_t = c(\\mu - r_t)dt + \\sigma dW_t$ if $c_1(t) = -c$, $c_2(t) = c\\mu$, $\\sigma_1(t) = 0$ and $\\sigma_2(t) = \\sigma$ for some positive constants $c$,$\\mu$ and $\\sigma$.\n",
    "- The homogeneous linear SDE if $c_2(t) = \\sigma_2(t) = 0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c95a8",
   "metadata": {},
   "source": [
    "(a) Show that the process\n",
    "\n",
    "$$\n",
    "X_t = X_0e^{ct} + \\sigma e^{ct}\\int_0^t e^{-cs}dW_s\n",
    "$$\n",
    "solves the Langevin SDE for a constant initial condition $X_0$. (This solution is called Ornstein-Uhlenbeck process.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c58bd8a",
   "metadata": {},
   "source": [
    "Let us show that the process defined in (a) solves the Langevin SDE for a constant initial condition $X_0$. We have to see that:\n",
    "$$\n",
    "dX_t = cX_t dt + \\sigma dW_t\n",
    "$$\n",
    "Notice that we can multiply the process $(X_t)_{t\\geq 0}$ by the factor $e^{-ct}$, such that:\n",
    "$$\n",
    "e^{-ct}X_t = e^{-ct}X_0e^{ct} + \\sigma e^{ct}e^{-ct}\\int_0^{t}e^{-cs}dW_s = X_0 + \\sigma\\int_0^{t}e^{-cs}dW_s.\n",
    "$$\n",
    "Notice that we can define some $(Y_t)_{t\\geq 0}$ random process such that, given the function $f(t,x) = e^{-ct}x$:\n",
    "$$\n",
    "Y_t := f(t,X_t) = X_0 + \\sigma \\int_0^te^{-cs}dW_s.\n",
    "$$\n",
    "Notice that $Y_t$ is an Itô process, since it can be written in the following integral form.\n",
    "$$\n",
    "Y_t = Y_0 + \\int_0^t \\mu_sds + \\int_0^t \\sigma_s dW_s = Y_0 + \\int_0^t \\sigma e^{-cs}dW_s.\n",
    "$$ Take $Y_0 = X_0$, and $\\mu_s = 0$ and $\\sigma_s = \\sigma e^{-cs}$, for the given constant $\\sigma$.\n",
    "\n",
    "Notice that we can also define the function $g(t,y) = e^{ct}y$ and, for the random process $Y_t$:\n",
    "$$\n",
    "g(t,Y_t) =e^{ct}Y_t = X_0 e^{ct} + e^{ct}\\sigma\\int_0^te^{-cs}dW_s = X_t\n",
    "$$ \n",
    "for all $0 \\leq t \\leq T$.\n",
    "\n",
    "Also, note that $g : \\mathbb{R}^2\\to \\mathbb{R}$ is smooth. Therefore, we can apply the Itô's formula (second version), and:\n",
    "$$\n",
    "dg(t,Y_t) = g_t(t,Y_t)dt + g_y(t,Y_t)dY_t + \\frac{1}{2}g_{yy}(t,Y_t)d[Y]_t.\n",
    "$$\n",
    "But:\n",
    "- $g_t(t,y) = \\frac{d}{dt}g(t,y) = c g(t,y)$\n",
    "- $g_y(t,y) = \\frac{d}{dy}g(t,y) = e^{ct}$\n",
    "- $g_{yy}(t,y) = \\frac{d^2}{dy^2}g(t,y) = \\frac{d}{dy} g_y(t,y) = 0$\n",
    "And:\n",
    "- $d[Y]_t = \\sigma_t^2 dt = (\\sigma e^{-ct})^2dt = \\sigma^2 e^{-2ct} dt$.\n",
    "\n",
    "Substituting:\n",
    "$$\n",
    "dg(t,Y_t) \\overset{(1)}{=} c g(t,Y_t)dt + e^{ct}dY_t + 0 \\overset{(2)}{=} cg(t,Y_t)dt + e^{ct} (\\sigma e^{-ct} dW_t) = cg(t,Y_t)dt + \\sigma dW_t.\n",
    "$$\n",
    "\n",
    "Where we have used:\n",
    "- (1) On the other hand, we set the whole term dependant on $g_{yy}$ to $0$ because the second derivative with respect to $y$ is equal to $0$.\n",
    "- (2) $(Y_t)_{t\\geq 0}$ is an Itô process, and we can write it in an integral form as we did above or we can also write it in a differential form: $dY_t = \\mu_tdt + \\sigma_t dW_t$. But, since we took $\\mu_t = 0$ and $\\sigma_t = \\sigma e^{-ct}$, the differential form is:\n",
    "$$\n",
    "dY_t = \\sigma e^{-ct}dW_t.\n",
    "$$\n",
    "\n",
    "As a result, we obtained:\n",
    "$$\n",
    "dg(t,Y_t) = dX_t = cX_t dt + \\sigma dW_t,\n",
    "$$ \n",
    "substituting $g(t,Y_t) = X_t$. But notice that this expression is, effectively, the Langevin SDE. Therefore, we have seen that $X_t = X_0e^{ct} + \\sigma e^{ct}\\int_0^t e^{-cs}dW_s$ effectively solves the Langevin PDE for a constant initial condition $X_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c3371",
   "metadata": {},
   "source": [
    "(b) Show that the process\n",
    "$$\n",
    "r_t = r_0 e^{-ct} + \\mu(1-e^{-ct}) + \\sigma e^{-ct}\\int_0^te^{cs}dW_s,\n",
    "$$\n",
    "solves the Vasicek interest rate SDE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42c198",
   "metadata": {},
   "source": [
    "Let us show that the process defined in (b) solves the Vasicek interest rate SDE for a constant $r_0$. We have to see that:\n",
    "$$\n",
    "dr_t = c(\\mu - r_t)dt + \\sigma dW_t\n",
    "$$\n",
    "Notice that we can multiply the process $(r_t)_{t\\geq 0}$ by the factor $e^{ct}$, such that:\n",
    "$$\n",
    "e^{ct}r_t = e^{ct}r_0e^{-ct} + e^{ct}\\mu(1-e^{-ct}) + e^{ct}\\sigma e^{-ct}\\int_0^{t}e^{cs}dW_s = r_0 + \\mu(e^{ct} - 1) + \\sigma\\int_0^{t}e^{cs}dW_s.\n",
    "$$\n",
    "Notice that we can define some $(Y_t)_{t\\geq 0}$ random process such that, given the function $f(t,x) = e^{ct}x$:\n",
    "$$\n",
    "Y_t := f(t,r_t) = r_0 + \\mu(e^{ct} - 1) + \\sigma\\int_0^{t}e^{cs}dW_s.\n",
    "$$\n",
    "Notice that $Y_t$ is an Itô process, since it can be written in the following integral form.\n",
    "$$\n",
    "Y_t = Y_0 + \\int_0^t \\mu_sds + \\int_0^t \\sigma_s dW_s = r_0 + \\mu(e^{ct} - 1) + \\sigma\\int_0^{t}e^{cs}dW_s.\n",
    "$$\n",
    "Take $Y_0 = r_0$, and $\\mu_s = c \\mu e^{cs}$ and $\\sigma_s = \\sigma e^{cs}$, for the given constants $\\mu$ and $\\sigma$. Let us show that in more detail:\n",
    "$$\n",
    "Y_t = Y_0 + \\int_0^t c\\mu e^{cs}ds + \\int_0^t \\sigma e^{cs} dW_s = Y_0 + c\\mu \\int_0^t e^{cs}ds + \\sigma \\int_0^t e^{cs}dW_s = Y_0 + c\\mu \\frac{e^{cx}}{c} + \\sigma \\int_0^{t} e^{cs}dW_s,\n",
    "$$\n",
    "Which is exactly the expression that we have for $Y_t$.\n",
    "\n",
    "Notice that we can also define the function $g(t,y) = e^{-ct}y$ and, for the random process $Y_t$:\n",
    "$$\n",
    "g(t,Y_t) =e^{-ct}Y_t = r_0 e^{-ct} + e^{-ct}\\mu(e^{ct}-1) + e^{-ct}\\sigma\\int_0^te^{-cs}dW_s = r_t\n",
    "$$ \n",
    "for all $0 \\leq t \\leq T$.\n",
    "\n",
    "Also, note that $g : \\mathbb{R}^2\\to \\mathbb{R}$ is smooth. Therefore, we can apply the Itô's formula (second version), and:\n",
    "$$\n",
    "dg(t,Y_t) = g_t(t,Y_t)dt + g_y(t,Y_t)dY_t + \\frac{1}{2}g_{yy}(t,Y_t)d[Y]_t.\n",
    "$$\n",
    "But:\n",
    "- $g_t(t,y) = \\frac{d}{dt}g(t,y) = -c g(t,y)$\n",
    "- $g_y(t,y) = \\frac{d}{dy}g(t,y) = e^{-ct}$\n",
    "- $g_{yy}(t,y) = \\frac{d^2}{dy^2}g(t,y) = \\frac{d}{dy} g_y(t,y) = 0$\n",
    "And:\n",
    "- $d[Y]_t = \\sigma_t^2 dt = (\\sigma e^{ct})^2dt = \\sigma^2 e^{2ct} dt$.\n",
    "\n",
    "Substituting:\n",
    "$$\n",
    "dg(t,Y_t) \\overset{(1)}{=} -c g(t,Y_t)dt + e^{-ct}dY_t + 0 \\overset{(2)}{=} cg(t,Y_t)dt + e^{-ct} (\\mu e^{ct}dt + \\sigma e^{ct} dW_t) = -cg(t,Y_t)dt + \\mu dt + \\sigma dW_t. = (\\mu - cg(t,Y_t))dt + \\sigma dW_t.\n",
    "$$\n",
    "\n",
    "Where we have used:\n",
    "- (1) On the other hand, we set the whole term dependant on $g_{yy}$ to $0$ because the second derivative with respect to $y$ is equal to $0$.\n",
    "- (2) $(Y_t)_{t\\geq 0}$ is an Itô process, and we can write it in an integral form as we did above or we can also write it in a differential form: $dY_t = \\mu_tdt + \\sigma_t dW_t$. But, since we took $\\mu_t = c\\mu e^{ct}$ and $\\sigma_t = \\sigma e^{ct}$, the differential form is:\n",
    "$$\n",
    "dY_t = \\mu e^{ct}dt + \\sigma e^{ct}dW_t.\n",
    "$$\n",
    "\n",
    "As a result, we obtained:\n",
    "$$\n",
    "dg(t,Y_t) = dr_t = (\\mu - cr_t dt) + \\sigma dW_t,\n",
    "$$ \n",
    "substituting $g(t,Y_t) = r_t$. But notice that this expression is, effectively, the Vasicek SDE. Therefore, we have seen that $r_t = r_0e^{-ct} + \\mu(1-e^{-ct}) + \\sigma e^{-ct}\\int_0^t e^{cs}dW_s$ effectively solves the Vasicek PDE for a constant initial condition $r_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21bc40",
   "metadata": {},
   "source": [
    "(c) Show that the process $X_t = X_0\\exp\\{\\int_0^t (c_1(s) - \\sigma_1^2(s)/2)ds + \\int_0^t \\sigma_1(s)dW_s\\}$ solves \n",
    "$$\n",
    "dX_t = X_t c_1(t)dt + \\sigma_1(t)X_tdW_t\n",
    "$$\n",
    "the homogeneous linear SDE. This solution is called generalized geometric Brownian motion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46008a3f",
   "metadata": {},
   "source": [
    "Let us consider the process $X_t$. Let us do the following manipulations.\n",
    "\n",
    "$$\n",
    "\\frac{X_t}{X_0} = \\exp\\{\\int_0^t (c_1(s) - \\sigma_1^2(s)/2)ds + \\int_0^t\\sigma_1(s)dW_s\\}\n",
    "$$\n",
    "Now, let us take logarithms:\n",
    "$$\n",
    "\\log(\\frac{X_t}{X_0}) = \\log(\\exp\\{\\int_0^t (c_1(s) - \\sigma_1^2(s)/2)ds + \\int_0^t\\sigma_1(s)dW_s\\})\n",
    "$$\n",
    "We can simplify further:\n",
    "$$\n",
    "\\log(X_t) - \\log(X_0) = \\int_0^t (c_1(s) - \\sigma_1^2(s)/2)ds + \\int_0^t\\sigma_1(s)dW_s\n",
    "$$\n",
    "Let us now define the function $f(x) = \\log(x)$. Notice that defining the process $Y_t = \\log(X_t)$, we observe that:\n",
    "$$\n",
    "Y_t = Y_0 + \\int_0^t (c_1(s) - \\sigma_1^2(s)/2)ds + \\int_0^t\\sigma_1(s)dW_s.\n",
    "$$\n",
    "But taking $\\mu_s = (c_1(s) - \\sigma_1^2(s)/2)$ and $\\sigma_s = \\sigma_1(s)$, then we just represented $Y_t$ as an Itô process through its integral form.\n",
    "\n",
    "Therefore, defining the function $g(y) = e^{y}$, we notice that $g: \\mathbb{R}\\to \\mathbb{R}$ is a smooth function and therefore we can apply the Itô's formula (first version) for $g(Y_t) = e^{Y_t}$:\n",
    "$$\n",
    "dg(Y_t) = g'(Y_t)dY_t + \\frac{1}{2}g''(Y_t) d[Y]_t\n",
    "$$\n",
    "\n",
    "But:\n",
    "- $d[Y]_t = \\sigma_t^2dt = \\sigma_1(t)^2 dt$\n",
    "- $dY_t = \\mu_t dt + \\sigma_t dW_t = (c_1(t)-\\sigma_1^2(t)/2)dt + \\sigma_1(t)dW_t$\n",
    "- $g'(y) = g''(y) = e^y$\n",
    "\n",
    "Substituting:\n",
    "$$\n",
    "dg(y) = g(y)((c_1(t)-\\sigma_1^2(t)/2)dt + \\sigma_1(t)dW_t) + \\frac{1}{2}g(y)\\sigma_1(t)^2dt = g(y)\\left((c_1(t)-\\sigma_1^2(t)/2 + \\sigma_1^2(t)/2)dt + \\sigma_1(t)dW_t\\right)\n",
    "$$\n",
    "\n",
    "And, simplifying a bit:\n",
    "$$\n",
    "dX_t = X_t\\left((c_1(t))dt + \\sigma_1(t)dW_t\\right)\n",
    "$$\n",
    "Which is, indeed the homogeneous linear SDE we intended to solve. Therefore, the proposed solution $X_t$ effectively solves the SDE that we wanted to solve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc859c5",
   "metadata": {},
   "source": [
    "(d) Determine the expectations and the variances of all the three solutions for problems (a)-(c) for a constant initial condition $X_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fb491",
   "metadata": {},
   "source": [
    "(a) Let us first find the expectation and the variance of the stochastic process:\n",
    "$$\n",
    "X_t = X_0e^{ct} + \\sigma e^{ct}\\int_0^t e^{-cs}dW_s\n",
    "$$\n",
    "where $X_0$ is the constant initial condition $X_0$, $c$ and $\\sigma$ are constants and $W_t$ is a standard Brownian motion.\n",
    "\n",
    "Notice that we have two terms: $X_0e^{ct}$, which is deterministic, and $\\sigma e^{ct}\\int_0^t e^{-cs}dW_s$, which is stochastic.\n",
    "\n",
    "The expectation of $X_t$ is:\n",
    "$$\n",
    "\\mathbb{E}[X_t] = \\mathbb{E}\\left[X_0e^{ct} + \\sigma e^{ct}\\int_0^{t}e^{-cs}dW_s\\right] \\overset{(1)}{=} \\mathbb{E}[X_0e^{ct}] + \\sigma e^{ct}\\mathbb{E}\\left[\\int_0^t e^{-cs}dW_s\\right].\n",
    "$$\n",
    "- (1) Linearity of expectation\n",
    "- Now, since $X_0e^{ct}$ is deterministic, its expectation is \n",
    "$$\n",
    "\\mathbb{E}[X_0e^{ct}] = X_0 e^{ct}\n",
    "$$\n",
    "- On the other hand, the expectation of $\\int_0^te^{-cs}dW_s$ is zero, since it is an integral which is based on infinitesimal increments of a Brownian motion. Recall that the increments of a Brownian motion are normally distributed with $W_{t + h} - W_t \\sim N(0, h)$. Therefore, they have mean $0$. Let us see this in more detail. Suppose we have an integral $\\int_0^t f(s)dW_s$ for $f(s)$ a deterministic, measurable function. Then\n",
    "$$\n",
    "\\mathbb{E}\\left[\\int_0^t f(s)dW_s\\right] = \\mathbb{E}\\left[\\lim_{n\\to\\infty}\\sum_{i=0}^{n-1}f(t_i)(W_{t_{i+1}}-W_{t_i})\\right] = \\lim_{n\\to\\infty}\\sum_{i=0}^{n-1}f(t_i)\\mathbb{E}\\left[(W_{t_{i+1}}-W_{t_i})\\right].\n",
    "$$\n",
    "But now, using $W_{t_{i+1}}-W_{t_i} \\sim N(0, t_{i+1}-t_i)$, and this implies $\\mathbb{E}\\left[W_{t_{i+1}}-W_{t_i}\\right] = 0$. Therefore, each term in the sum vanishes, and hence $\\mathbb{E}\\left[\\int_0^t f(s)dW_s\\right] = 0$.\n",
    "\n",
    "Back to the expectation of $X_t$:\n",
    "$$\n",
    "\\mathbb{E}[X_t] = \\mathbb{E}[X_0e^{ct}] + \\sigma e^{ct}\\mathbb{E}\\left[\\int_0^t e^{-cs}dW_s\\right] = X_0e^{ct} + 0 = X_0e^{ct}.\n",
    "$$\n",
    "Let us now consider the variance of $X_t$.\n",
    "\n",
    "The variance of $X_t$ is:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X_t) = \\mathbb{E}[X_t^2] - \\mathbb{E}[X_t]^2.\n",
    "$$\n",
    "Let us compute $\\mathbb{E}[X_t^2]$:\n",
    "$$\n",
    "X_t^2 = \\left(X_0e^{ct}+\\sigma e^{ct}\\int_0^te^{-cs}dW_s\\right)^2 = (X_0e^{ct})^2+2X_0e^{ct}\\sigma e^{ct}\\int_0^te^{-cs}dW_s + \\left(\\sigma e^{ct}\\int_0^t e^{-cs}dW_s\\right)^2.\n",
    "$$\n",
    "Considering term by term:\n",
    "- $(X_0e^{ct})^2$ is deterministic, hence:\n",
    "$$\n",
    "\\mathbb{E}\\left[(X_0e^{ct})^2\\right] = (X_0e^{ct})^2.\n",
    "$$\n",
    "- The cross term involves $\\int_0^te^{-cs}dW_s$, which has zero expectation, by the argument above. Therefore:\n",
    "$$\n",
    "\\mathbb{E}\\left[2X_0e^{ct}\\sigma e^{ct}\\int_0^te^{-cs}dW_s\\right] = 0.\n",
    "$$\n",
    "- The expectation of the third term is given by the Itô isometry:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\left(\\sigma e^{ct}\\int_0^t e^{-cs}dW_s\\right)^2\\right] = \\sigma^2e^{2ct}\\int_0^t (e^{-cs})^2ds = \\int_0^te^{-2cs}ds.\n",
    "$$\n",
    "Let us now evaluate the following integral:\n",
    "$$\n",
    "\\int_0^t e^{-2cs}ds = \\frac{1}{-2c}\\left[e^{-2cs}\\right]^t_0 = \\frac{1}{2c}(1-e^{-2ct}).\n",
    "$$\n",
    "Therefore, the expectation of the whole term is:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\left(\\sigma e^{ct}\\int_0^t e^{-cs}dW_s\\right)^2\\right] = \\sigma^2e^{2ct}\\frac{1}{2c}(1-e^{-2ct}).\n",
    "$$\n",
    "\n",
    "Combining all the terms:\n",
    "$$\n",
    "\\mathbb{E}\\left[X_t^2\\right] = (X_0e^{ct})^2 + 0 + \\sigma^2e^{2ct}\\frac{1}{2c}(1-e^{-2ct}).\n",
    "$$\n",
    "\n",
    "Also, from earlier, $\\mathbb{E}[X_t]^2 = (X_0e^{ct})^2$.\n",
    "\n",
    "Finally, we subtract the terms, and we obtain:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X_t) = \\mathbb{E}[X_t^2]-(\\mathbb{E}[X_t])^2 = (X_0e^{ct})^2 + 0 + \\sigma^2e^{2ct}\\frac{1}{2c}(1-e^{-2ct}) - (X_0e^{ct})^2 = \\sigma^2e^{2ct}\\frac{1}{2c}(1-e^{-2ct}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a93dbec",
   "metadata": {},
   "source": [
    "(b) Let us now find the expectation and the variance of the stochastic process:\n",
    "$$\n",
    "r_t = r_0 e^{-ct} + \\mu(1-e^{-ct}) + \\sigma e^{-ct}\\int_0^te^{cs}dW_s,\n",
    "$$\n",
    "\n",
    "where $r_0$ is the constant initial condition $r_0$, $c$, $\\mu$ and $\\sigma$ are constants and $W_t$ is a standard Brownian motion.\n",
    "\n",
    "Notice that we have three terms: $r_0e^{-ct}$, which is deterministic, $\\mu (1-e^{-ct})$, which is also deterministic, and $\\sigma e^{-ct}\\int_0^t e^{cs}dW_s$, which is stochastic.\n",
    "\n",
    "The expectation of $r_t$ is:\n",
    "$$\n",
    "\\mathbb{E}[r_t] = \\mathbb{E}\\left[r_0 e^{-ct} + \\mu(1-e^{-ct}) + \\sigma e^{-ct}\\int_0^te^{cs}dW_s\\right] \\overset{(1)}{=} \\mathbb{E}[r_0e^{-ct}] + \\mathbb{E}[\\mu(1-e^{-ct})] + \\sigma e^{-ct}\\mathbb{E}\\left[\\int_0^t e^{cs}dW_s\\right].\n",
    "$$\n",
    "- (1) Linearity of expectation\n",
    "- Now, since $r_0e^{-ct}$ is deterministic, its expectation is \n",
    "$$\n",
    "\\mathbb{E}[r_0e^{ct}] = r_0 e^{ct}\n",
    "$$\n",
    "And similarly, for:\n",
    "$$\n",
    "\\mathbb{E}[\\mu(1-e^{-ct})] = \\mu(1-e^{-ct}.)\n",
    "$$\n",
    "- On the other hand, the expectation of $\\int_0^te^{cs}dW_s$ is zero, since it is an integral which is based on infinitesimal increments of a Brownian motion. Refer to the argument that we used above, which is useful in this case as well, given $f(s) = e^{cs}$.\n",
    "\n",
    "Back to the expectation of $r_t$:\n",
    "$$\n",
    "\\mathbb{E}[r_t] = r_0e^{-ct} + \\mu(1-e^{-ct}) + 0 = r_0e^{-ct} + \\mu(1-e^{-ct}).\n",
    "$$\n",
    "Let us now consider the variance of $r_t$.\n",
    "\n",
    "The variance of $r_t$ is:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(r_t) = \\mathbb{E}[r_t^2] - \\mathbb{E}[r_t]^2.\n",
    "$$\n",
    "Let us compute $\\mathbb{E}[r_t^2]$:\n",
    "$$\n",
    "r_t^2 = \\left(r_0 e^{-ct} + \\mu(1-e^{-ct}) + \\sigma e^{-ct}\\int_0^te^{cs}dW_s\\right)^2 = \n",
    "$$\n",
    "$$\n",
    "= (r_0e^{-ct})^2 + (\\mu(1-e^{-ct}))^2 + \\left(\\sigma e^{-ct}\\int_0^t e^{cs}dW_s\\right)^2 + 2r_0e^{-ct}\\mu(1-e^{-ct}) +\n",
    "$$\n",
    "$$\n",
    "+2r_0e^{-ct}\\sigma e^{-ct}\\int_0^te^{cs}dW_s + 2\\mu(1-e^{-ct})\\sigma e^{-ct}\\int_0^t e^{cs}dW_s.\n",
    "$$\n",
    "Considering term by term:\n",
    "- $(r_0e^{-ct})^2$ is deterministic, hence:\n",
    "$$\n",
    "\\mathbb{E}\\left[(r_0e^{-ct})^2\\right] = (r_0e^{-ct})^2.\n",
    "$$\n",
    "- The second term is also deterministic, and hence: \n",
    "$$\n",
    "\\mathbb{E}\\left[(\\mu(1-e^{-ct}))^2\\right] = (\\mu(1-e^{-ct}))^2.\n",
    "$$\n",
    "- The expectation of the third term is given by the Itô isometry:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\left(\\sigma e^{-ct}\\int_0^t e^{cs}dW_s\\right)^2\\right] = \\sigma^2e^{2ct}\\int_0^t (e^{cs})^2ds = \\int_0^te^{2cs}ds.\n",
    "$$\n",
    "Let us now evaluate the following integral:\n",
    "$$\n",
    "\\int_0^t e^{2cs}ds = \\frac{1}{2c}\\left[e^{2cs}\\right]^t_0 = \\frac{1}{2c}(e^{2ct}-1).\n",
    "$$\n",
    "- We set to zero the expectations of the terms $2r_0e^{-ct}\\sigma e^{-ct}\\int_0^t e^{cs}dW_s$ and $2\\mu(1-e^{-ct})\\sigma e^{-ct}\\int_0^t e^{cs}dW_s$, because it involves Wiener integrals, which we know that have expectation $0$ by the argumentation made for statement (a). \n",
    "\n",
    "- The only cross term that survives is $2r_0e^{-ct}\\mu(1-e^{-ct})$, which is deterministic, therefore:\n",
    "$$\n",
    "\\mathbb{E}\\left[2r_0e^{-ct}\\mu(1-e^{-ct})\\right] = 2r_0e^{-ct}\\mu(1-e^{-ct}).\n",
    "$$\n",
    "\n",
    "Therefore, the expectation of the whole term is:\n",
    "$$\n",
    "\\mathbb{E}[r_t^2] = \\mathbb{E}\\left[\\left(\\sigma e^{-ct}\\int_0^t e^{cs}dW_s\\right)^2\\right] = (r_0e^{-ct})^2 + (\\mu(1-e^{-ct}))^2 + \\sigma^2e^{-2ct}\\frac{1}{2c}(e^{2ct}-1) + 2r_0e^{-ct}\\mu(1-e^{-ct}).\n",
    "$$\n",
    "\n",
    "Also, from earlier, $\\mathbb{E}[r_t]^2 = (r_0e^{-ct} + \\mu(1-e^{-ct}))^2$.\n",
    "\n",
    "Finally, we subtract the terms, and we obtain:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X_t) = \\mathbb{E}[X_t^2]-(\\mathbb{E}[X_t])^2 = (r_0e^{-ct})^2 + (\\mu(1-e^{-ct}))^2 + \\sigma^2e^{-2ct}\\frac{1}{2c}(e^{2ct}-1) + 2r_0e^{-ct}\\mu(1-e^{-ct}) - (r_0e^{-ct} + \\mu(1-e^{-ct}))^2.\n",
    "$$\n",
    "Therefore, simplifying the square, the variance of the solution process for the Vasicek SDE proposed in (b) is:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X_t) = \\sigma^2e^{-2ct}\\frac{1}{2c}(e^{2ct}-1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7914e5",
   "metadata": {},
   "source": [
    "Lastly, let us compute expectation and variance of the proposed solution for the homogeneous linear SDE. Recall the proposed solution for (c):\n",
    "$$\n",
    "X_t = X_0\\exp\\{\\int_0^t (c_1(s) - \\sigma_1^2(s)/2)ds + \\int_0^t \\sigma_1(s)dW_s\\}\n",
    "$$\n",
    "for $X_0$ constant, $c_1(s)$ and $\\sigma_1(s)$ deterministic functions of $s$ and $W_s$ a standard Brownian motion.\n",
    "\n",
    "Let us express $X_t$ in the following way:\n",
    "$$\n",
    "X_t = X_0 \\exp\\{A_t + M_t\\}\n",
    "$$\n",
    "with:\n",
    "- $A_t = \\int_0^t\\left(c_1(s) - \\frac{\\sigma_1(s)^2}{2}\\right)ds$, deterministic, and\n",
    "- $M_t = \\int_0^t\\sigma_1(s)dW_s$, stochastic.\n",
    "\n",
    "Let us first compute the expectation of $X_t$:\n",
    "$$\n",
    "\\mathbb{E}[X_t] = X_0 \\mathbb{E}\\left[\\exp\\{A_t + M_t\\}\\right] = X_0 \\mathbb{E}\\left[\\exp\\{A_t\\} \\exp\\{M_t\\}\\right] = X_0 \\exp\\{A_t\\}\\mathbb{E}\\left[\\exp\\{M_t\\}\\right].\n",
    "$$\n",
    "Now, we are going to prove that, for $M_t$ as defined above:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\exp\\{M_t\\}\\right] = \\exp\\{\\frac{1}{2}\\mathbb{V}\\text{ar}(M_t)\\}.\n",
    "$$\n",
    "Notice that, given that $M_t$ is a linear combination of Brownian motion increments, $M_t$ is normally distributed. The mean of $M_t$ is, by the argumentation made above (that we are recurrently referring to), $0$. And, its variance, is hence determined completely by the Itô isometry, since \n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(M_t) = \\mathbb{E}[M_t^2] = \\mathbb{E}\\left[\\left(\\int_0^t\\sigma(s)dW_s\\right)^2\\right] = \\int_0^t\\sigma(s)^2ds.\n",
    "$$\n",
    "The expectation of the exponential of $M_t$ is:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\exp\\{M_t\\}\\right] = \\int_{-\\infty}^{\\infty}\\exp(x)f_{M_t}(x)dx\n",
    "$$\n",
    "where $f_{M_t}(x)$ is the probability density function of $M_t$, given by the normal distribution. Let us denote $v_t = \\int_0^t \\sigma(s)^2ds$. Then, the probability density function of $M_t$ is given by:\n",
    "$$\n",
    "f_{M_t}(x) = \\frac{1}{\\sqrt{2\\pi v_t}}\\exp\\left(-\\frac{x^2}{2v_t}\\right).\n",
    "$$\n",
    "Hence:\n",
    "$$\n",
    "\\mathbb{E}[\\exp\\{M_t\\}] = \\int_{-\\infty}^\\infty \\exp\\{x\\}\\frac{1}{\\sqrt{2\\pi v_t}}\\exp\\left(-\\frac{x^2}{2v_t}\\right).\n",
    "$$\n",
    "Combining the exponents:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\exp\\{M_t\\}\\right] = \\frac{1}{\\sqrt{2\\pi v_t}}\\int_{-\\infty}^{\\infty}\\exp\\left(-\\frac{x^2}{2v_t} + x\\right)dx\n",
    "$$\n",
    "Let us now manipulate the exponent. The exponent $-\\frac{x^2}{2v_t} + x = -\\frac{1}{2v_t}(x^2 - 2v_tx)$.\n",
    "We now complete the square for $x^2 - 2v_tx$, and:\n",
    "$$\n",
    "x^2 - 2v_tx = (x-v_t)^2 - v_t^2.\n",
    "$$\n",
    "Substituting back to the exponent:\n",
    "$$\n",
    "-\\frac{x^2}{2v_t} + x = -\\frac{1}{2v_t}((x-v_t)^2-v_t^2) = -\\frac{(x-v_t)^2}{2v_t} + \\frac{v_t}{2}.\n",
    "$$\n",
    "Therefore:\n",
    "$$\n",
    "\\mathbb{E}[\\exp\\{M_t\\}] = \\frac{1}{\\sqrt{2\\pi v_t}}\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{(x-v_t)^2}{2v_t}\\right)\\exp\\left(\\frac{v_t}{2}\\right)dx\n",
    "$$\n",
    "And, factoring out $\\exp(v_t/2)$:\n",
    "$$\n",
    "\\mathbb{E}[\\exp\\{M_t\\}] = \\exp\\left(\\frac{v_t}{2}\\right)\\frac{1}{\\sqrt{2\\pi v_t}}\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{(x-v_t)^2}{2v_t}\\right)dx.\n",
    "$$\n",
    "Now, notice that we can evaluate the remaining integral, since notice that it is the normalization factor of a Normal distribution with mean $v_t$ and variance $v_t$:\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty}\\exp\\left(-\\frac{(x-v_t)^2}{2v_t}\\right)dx = \\sqrt{2\\pi v_t}.\n",
    "$$\n",
    "And, lastly:\n",
    "$$\n",
    "\\mathbb{E}[\\exp\\{M_t\\}] = \\exp\\{\\frac{v_t}{2}\\} = \\exp\\left(\\frac{1}{2}\\int_0^t \\sigma(s)^2ds\\right).\n",
    "$$\n",
    "\n",
    "Therefore, we obtain that the expectation of $X_t$ as the proposed solution of $(c)$ is:\n",
    "$$\n",
    "\\mathbb{E}[X_t] = X_0 \\exp\\left(A_t + \\frac{1}{2}\\int_0^t\\sigma_1(s)^2ds\\right)\n",
    "$$\n",
    "Recalling that $A_t = \\int_0^t\\left(c_1(s) - \\frac{\\sigma_1^2(s)}{2}\\right)ds$. Substituting:\n",
    "$$\n",
    "\\mathbb{E}[X_t] = X_0\\exp\\left(\\int_0^t c_1(s)ds - \\frac{1}{2}\\int_0^t \\sigma_1(s)^2ds + \\frac{1}{2}\\int_0^t\\sigma_1(s)^2ds\\right) = X_0\\exp\\left(\\int_0^t c_1(s)ds \\right)\n",
    "$$\n",
    "We therefore notice, sadly, that we actually do not needed to compute the complicated integral, but it was useful as an exercise :).\n",
    "\n",
    "Now, turning to the variance of $X_t$:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X_t) = \\mathbb{E}[X_t^2] - (\\mathbb{E}[X_t])^2.\n",
    "$$\n",
    "\n",
    "First, let us compute $\\mathbb{E}[X_t^2]$, the square of $X_t$ is:\n",
    "$$\n",
    "X_t^2 = X_0^2\\exp\\{2A_t + 2M_t\\}.\n",
    "$$\n",
    "Thus:\n",
    "$$\n",
    "\\mathbb{E}[X_t^2] = X_0^2\\mathbb{E}[\\exp\\{2A_t + 2M_t\\}].\n",
    "$$\n",
    "Similar as before, we decompose $2A_t + 2M_t$ into deterministic $(2A_t)$ and stochastic $(2M_t)$ parts:\n",
    "$$\n",
    "\\exp\\{2A_t + 2M_t\\} = \\exp\\{2A_t\\}\\exp\\{2M_t\\}.\n",
    "$$\n",
    "Given that $2A_t$ is deterministic, we get:\n",
    "$$\n",
    "\\mathbb{E}[X_t^2]=  X_0^2\\exp\\{2A_t\\}\\mathbb{E}[\\exp\\{2M_t\\}].\n",
    "$$\n",
    "Now, we can substitute $2A_t = 2\\int_0^t(c_1(s) - \\frac{\\sigma_1^2(s){2}})ds$ and $2M_t = \\exp\\left(\\int_0^t \\sigma_1(s)^2ds\\right)$:\n",
    "$$\n",
    "\\mathbb{E}[X_t^2] = X_0^2\\exp\\left(2\\int_0^tc_1(s)ds\\right)\n",
    "$$\n",
    "From earlier, $\\mathbb{E}[X_t]^2 = X_0^2\\exp\\left(2\\int_0^tc_1(s)ds\\right)$.\n",
    "\n",
    "Therefore, note that $\\mathbb{E}[X_t]^2 = \\mathbb{E}[X_t^2]$, and, therefore:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X_t) = 0.\n",
    "$$\n",
    "This result indicates that the variance of $X_t$ is $0$. We can explain this result by the structure of the process $X_t$, where the stochastic term $\\int_0^t \\sigma_1(s)dW_s$ is integrated within the exponential, which introduces a deterministic compensating factor in the expectation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17d1cc",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
